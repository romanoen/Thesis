{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate one tweet similar to the following on...</td>\n",
       "      <td>\"Excited for the start of #COP26 in Glasgow üè¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate one tweet similar to the following on...</td>\n",
       "      <td>\"#cdnpoli #cdnmedia: Imagining a media game-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate one tweet similar to the following on...</td>\n",
       "      <td>\"Reflecting on the silver lining of the pande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate one tweet similar to the following on...</td>\n",
       "      <td>\"Corruption personified: Greedy, dishonest, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generate one tweet similar to the following on...</td>\n",
       "      <td>\"@CNBC @GretaThunberg: Irony alerts as politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0  Generate one tweet similar to the following on...   \n",
       "1  Generate one tweet similar to the following on...   \n",
       "2  Generate one tweet similar to the following on...   \n",
       "3  Generate one tweet similar to the following on...   \n",
       "4  Generate one tweet similar to the following on...   \n",
       "\n",
       "                                            Response  \n",
       "0   \"Excited for the start of #COP26 in Glasgow üè¥...  \n",
       "1   \"#cdnpoli #cdnmedia: Imagining a media game-c...  \n",
       "2   \"Reflecting on the silver lining of the pande...  \n",
       "3   \"Corruption personified: Greedy, dishonest, s...  \n",
       "4   \"@CNBC @GretaThunberg: Irony alerts as politi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "\n",
    "mistral = pd.read_csv(\"../LLMs/Mixtral/responsesMixtral.csv\")\n",
    "mistral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete Emoji\n",
    "def delete_emojis(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].apply(delete_emojis)\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].apply(delete_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all the quotes from the columns\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.replace('\"', \"\").replace(\"'\", \"\")\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.replace('\"', \"\").replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove urls from both columns\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove every tagging of a user\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.replace(r'@\\S+', '', regex=True)\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.replace(r'@\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove every newline character\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.replace(r'\\n', ' ', regex=True)\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.replace(r'\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove every tab character\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.replace(r'\\t', ' ', regex=True)\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.replace(r'\\t', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove every other special character to be sure\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.replace(r'[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove every number\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.replace(r'\\d+', '', regex=True)\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.replace(r'\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all to lower case\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].str.lower()\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romanoelfken/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/romanoelfken/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/romanoelfken/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#lemmatize everything\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Download necessary ntkl data files\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(tag)) for token, tag in tagged_tokens]\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral[\"Generated Response\"] = mistral[\"Generated Response\"].apply(lemmatize_text)\n",
    "mistral[\"Original Tweet\"] = mistral[\"Original Tweet\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral.to_csv(\"llama3csv.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
