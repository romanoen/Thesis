{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  ahead cop key paragraph g text set stage actio...      1\n",
      "1  shameful display pettiness demand collective e...      1\n",
      "2  whats tip point transform global sustainabilit...      1\n",
      "3  climate crisis smoke screen real issue uk shoc...      1\n",
      "4  bad outcome person die million thats question ...      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load your data here\n",
    "data = pd.read_csv(\"llama3csv.csv\")\n",
    "\n",
    "# Assuming data has columns 'text' and 'label'\n",
    "gr = data[\"Generated Response\"].copy()\n",
    "ot = data[\"Original Tweet\"].copy()\n",
    "gr_df = pd.DataFrame({'text': gr, 'label': 1})\n",
    "ot_df = pd.DataFrame({'text': ot, 'label': 0})\n",
    "data = pd.concat([gr_df, ot_df], ignore_index=True, sort=False)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], data[\"label\"], test_size=0.2, random_state=42, stratify=data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(4, 4), max_features=11000)  # dynamic range of features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], data[\"label\"], test_size=0.2, random_state=42, stratify=data[\"label\"])\n",
    "\n",
    "# Remove NaN values from the split data\n",
    "X_train = X_train.dropna()\n",
    "X_test = X_test.dropna()\n",
    "y_train = y_train[X_train.index]\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for grid search\n",
    "param_grid_svm_lr = {\n",
    "    'C': [6.0, 2.0, 1.0, 0.95, 0.9, 0.8]\n",
    "}\n",
    "param_grid_rf = {\n",
    "    'min_samples_split': [8, 32, 128],\n",
    "    'max_features': [int(np.sqrt(X_train.shape[1])), int(0.02 * X_train.shape[1]), int(0.04 * X_train.shape[1]), int(0.06 * X_train.shape[1])]\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "svm = SVC(kernel='linear')\n",
    "lr = LogisticRegression(solver='liblinear', penalty='l2')\n",
    "rf = RandomForestClassifier(criterion='gini', oob_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for SVM\n",
    "grid_svm = GridSearchCV(svm, param_grid_svm_lr, cv=5, scoring='accuracy')\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# Grid search for Logistic Regression\n",
    "grid_lr = GridSearchCV(lr, param_grid_svm_lr, cv=5, scoring='accuracy')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "# Grid search for Random Forest\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SVM\n",
    "svm_best = grid_svm.best_estimator_\n",
    "y_pred_svm = svm_best.predict(X_test)\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_best = grid_lr.best_estimator_\n",
    "y_pred_lr = lr_best.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_best = grid_rf.best_estimator_\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine model outputs by labeling records as artificial if and only if all models agree\n",
    "y_pred_combined = (y_pred_svm & y_pred_lr & y_pred_rf)\n",
    "print(\"Combined Model Classification Report:\\n\", classification_report(y_test, y_pred_combined))\n",
    "print(\"Combined Model Accuracy:\", accuracy_score(y_test, y_pred_combined))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
